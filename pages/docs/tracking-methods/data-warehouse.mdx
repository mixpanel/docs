import { Tab, Tabs } from 'nextra-theme-docs'
import { Callout } from 'nextra/components'

import ExtendedTabs from '../../../components/ExtendedTabs/ExtendedTabs';
import { dwhItems } from '../../../utils/constants';

# Warehouse Connectors

## Overview

Warehouse Connectors enable you to load Mixpanel with data from data warehouses (DWH) like BigQuery, Snowflake, Databricks, and Redshift. By unifying business data with product usage events, you can answer many more questions in Mixpanel:
* What percentage of our Enterprise revenue uses the features we shipped last year?
* Did our app redesign reduce support tickets?
* Which account demographics have the best retention?
* We spent $50,000 on a marketing campaign, did the users we acquire stick around a month later?

In this guide, we'll walk through how to set up Warehouse Connectors. The integration is completely codeless, but you will need someone with access to your DWH to help with the initial set up.

## Getting Started

### Step 1: Connect a warehouse

Navigate to [Project Settings → Warehouse Sources](https://mixpanel.com/report/settings). Select your warehouse and follow the instructions to connect it. Note: you only need to do this once.

### Step 2: Load a warehouse table

Navigate to [Project Settings → Warehouse Data](https://mixpanel.com/report/settings) and click +Event Table.

Select a table (or view) representing an event from your warehouse and tell Mixpanel about the table. Once satisfied with the preview, click run and we’ll establish the sync. The initial load may take a few minutes depending on the size of the table, we show you progress as it’s happening.

🎉 Congrats, you’ve loaded your first warehouse table into Mixpanel! From this point onward, the table will be kept in sync with Mixpanel. You can now use this event throughout Mixpanel’s interface.

### Warehouse-Specific Walkthroughs

<ExtendedTabs urlParam="dwh" urlToItemsMap={dwhItems}>

<Tab>
    <div style={{position: 'relative', paddingBottom: '64.90384615384616%', height: 0}}>
        <iframe src="https://www.loom.com/embed/04f4ea75310744cdab477e1b47684db3?sid=3728258e-b860-431f-bdf2-cff508b2b19e"
            frameBorder="0"
            webkitallowfullscreen="true" mozallowfullscreen="true" allowFullScreen
            style={{position: 'absolute', 'top': 0, 'left': 0, 'width': '100%', 'height': '100%'}}>
        </iframe>
    </div>

        The BigQuery connector works by giving a Mixpanel service account the permission to read/write from BigQuery in your GCP project. You will need your GCP Project ID, which you can find in the URL of Google Cloud Console (https://console.cloud.google.com/bigquery?project=YOUR_GCP_PROJECT). You will also need the `gcloud` CLI.

</Tab>
<Tab>
    <div style={{position: 'relative', paddingBottom: '64.90384615384616%', height: 0}}>
        <iframe src="https://www.loom.com/embed/5dbaf37d9308404393417043551aed55"
            frameBorder="0"
            webkitallowfullscreen="true" mozallowfullscreen="true" allowFullScreen
            style={{position: 'absolute', 'top': 0, 'left': 0, 'width': '100%', 'height': '100%'}}>
        </iframe>
    </div>

    Complete the following steps to get your Snowflake connector up and running:
    1. Navigate to **Project Settings**, then select **Warehouse Sources**.
    2. Click on `+ Add Connection` and select **Snowflake**.
    3. You should see a new page to create your snowflake connector. In the first view, fill out the following fields before clicking  `Next`: 
        - Snowflake Account Name / URL
        - Username
        - Role
        - Authentication Type. We support both Password and Key Pair.
        Ensure that the corresponding commands have been successfully completed in your Snowflake instance.
            - For Password authentication:
                - Fill out the password field.
                - Copy the commands and run them within your Snowflake instance.
                - Be sure to fill out the password field in your command.
            - For Key Pair authentication:
                - Mixpanel will generate a secure key pair for your source per the Snowflake requirements.
                - The private key will be encrypted and stored securely, and used only when we need to communicate with your Snowflake instance.
                - Public key can be found in the suggested SQL to create your user.
    4. In the second view, you can click `Create Source` after completing the following:
        - Warehouse
            - Enter the name of your warehouse (default value: **MIXPANEL_IMPORT_WAREHOUSE**).
            - We recommend creating a separate warehouse for Mixpanel, and ensuring that Mixpanel has the appropriate role permissions to access it.
            - Run the commands below in Snowflake.
    3. You should see a new page to create your snowflake connector. In the first view, fill out the following fields before clicking  `Next`: 
        - Snowflake Account Name / URL
        - Username
        - Role
        - Authentication Type. We support both Password and Key Pair.
        Ensure that the corresponding commands have been successfully completed in your Snowflake instance.
            - For Password authentication:
                - Fill out the password field.
                - Copy the commands and run them within your Snowflake instance.
                - Be sure to fill out the password field in your command.
            - For Key Pair authentication:
                - Mixpanel will generate a secure key pair for your source per the Snowflake requirements.
                - The private key will be encrypted and stored securely, and used only when we need to communicate with your Snowflake instance.
                - Public key can be found in the suggested SQL to create your user.
    4. In the second view, you can click `Create Source` after completing the following:
        - Warehouse
            - Enter the name of your warehouse (default value: **MIXPANEL_IMPORT_WAREHOUSE**).
            - We recommend creating a separate warehouse for Mixpanel, and ensuring that Mixpanel has the appropriate role permissions to access it.
            - Run the commands below in Snowflake.
                ```jsx
                CREATE WAREHOUSE MIXPANEL_IMPORT_WAREHOUSE WITH WAREHOUSE_SIZE = XSMALL AUTO_SUSPEND = 60 AUTO_RESUME = TRUE INITIALLY_SUSPENDED = FALSE;
                GRANT USAGE ON WAREHOUSE MIXPANEL_IMPORT_WAREHOUSE TO ROLE MIXPANEL_IMPORT_ROLE;
                GRANT OPERATE ON WAREHOUSE MIXPANEL_IMPORT_WAREHOUSE TO ROLE MIXPANEL_IMPORT_ROLE;
                GRANT MONITOR ON WAREHOUSE MIXPANEL_IMPORT_WAREHOUSE TO ROLE MIXPANEL_IMPORT_ROLE; 
                ``` 
        - Storage Integration
            - This is required because Mixpanel will export the query results into a GCS bucket.
            - Default value: **MIXPANEL_IMPORT_STORAGE_INTEGRATION**
            
            ```jsx
            CREATE STORAGE INTEGRATION MIXPANEL_IMPORT_STORAGE_INTEGRATION
              TYPE = EXTERNAL_STAGE
              STORAGE_PROVIDER = 'GCS'
              ENABLED = TRUE
              STORAGE_ALLOWED_LOCATIONS = ("gcs://mixpanel-2946576-ca470bce1e1ed2ec");
            GRANT USAGE ON INTEGRATION MIXPANEL_IMPORT_STORAGE_INTEGRATION TO MIXPANEL_IMPORT_ROLE; 
            ```
            
        - Database (optional)
            - Enter the name of the database you want to grant permission to.
            - By default, we request read-only access.
            - Mixpanel does not store the access information. However, you can choose to provide more granular access if you desire.
            
            ```jsx
            GRANT USAGE ON DATABASE "<your_data_base>" TO ROLE MIXPANEL_IMPORT_ROLE;
            GRANT USAGE ON ALL SCHEMAS IN DATABASE "<your_data_base>" TO ROLE MIXPANEL_IMPORT_ROLE;
            GRANT SELECT ON ALL TABLES IN DATABASE "<your_data_base>" TO ROLE MIXPANEL_IMPORT_ROLE;
            GRANT SELECT ON ALL VIEWS IN DATABASE "<your_data_base>" TO ROLE MIXPANEL_IMPORT_ROLE;
            GRANT SELECT ON ALL MATERIALIZED VIEWS IN DATABASE "<your_data_base>" TO ROLE MIXPANEL_IMPORT_ROLE;
            ```
    
    *IP Allowed List*
    If you are using [Snowflake Network policy](https://docs.snowflake.com/en/user-guide/network-policies) to restrict access to your instance, you might need to add the following IP addresses to the allowed list.
    
    ```jsx
    34.31.112.201
    34.147.68.192
    35.184.21.33
    35.225.176.74
    35.204.164.122
    35.204.177.251
    ```
    
    *Mirror Sync Readiness*
    
    <Callout type="info">
      Mirror syncing is in early access and not available on all projects. Request access
      <a href="https://forms.gle/x8mbU6FVe5uHiVXF6">here</a>.
    </Callout>
    
    Mirror syncs use [Snowflake streams](https://docs.snowflake.com/en/user-guide/streams-intro) to track all changes (inserts, updates, and deletes) to source tables. [`CHANGE_TRACKING`](https://docs.snowflake.com/en/sql-reference/sql/alter-table) must be enabled on a Snowflake table in order for a Mirror sync to be created from it.
    ```jsx
    ALTER TABLE <database>.<schema>.<table> SET CHANGE_TRACKING = TRUE;
    ```
    
    When using Mirror syncs Mixpanel creates and manages Snowflake streams in the source warehouse and needs the `CREATE STREAM` permission on a Snowflake schema to store these streams. We recommend creating a new empty schema solely for Mixpanel. For example:
    ```jsx
    CREATE DATABASE IF NOT EXISTS MIXPANEL_STREAM_DATABASE;
    CREATE SCHEMA IF NOT EXISTS MIXPANEL_STREAM_DATABASE.MIXPANEL_STREAM_SCHEMA;
    
    -- Grant your Mixpanel role access to create streams in the schema
    GRANT USAGE ON DATABASE MIXPANEL_STREAM_DATABASE TO ROLE MIXPANEL_IMPORT_ROLE;
    GRANT USAGE ON SCHEMA MIXPANEL_STREAM_DATABASE.MIXPANEL_STREAM_SCHEMA TO ROLE MIXPANEL_IMPORT_ROLE;
    GRANT CREATE STREAM ON SCHEMA MIXPANEL_STREAM_DATABASE.MIXPANEL_STREAM_SCHEMA TO ROLE MIXPANEL_IMPORT_ROLE;
    ```
    
    To create a new Mirror-ready Snowflake source follow the steps above and fill out the additional two fields "Stream Database" and "Stream Schema" in step 4.
    
    To update an existing source to be Mirror-ready:
    1. Navigate to **Project Settings**, then select **Warehouse Sources**.
    2. Find the source to update. The source's card should include a note **Mirror: Additional Setup Required**. Click "Additional Setup Required" to be taken to the source configuration page.
    3. Fill in the two fields "Stream Database" and "Stream Schema". Press Save.
</Tab>
<Tab>
    <div style={{position: 'relative', paddingBottom: '64.90384615384616%', height: 0}}>
    <iframe src="https://www.loom.com/embed/56a21b31e75342498317cbb6f31285eb"
        frameBorder="0"
        webkitallowfullscreen="true" mozallowfullscreen="true" allowFullScreen
        style={{position: 'absolute', 'top': 0, 'left': 0, 'width': '100%', 'height': '100%'}}>
    </iframe>
</div>

The connection to Databricks only supports connecting directly to clusters. Connecting directly to jobs or SQL warehouses is not supported. The account used for the connection should have `can attach to` permissions to the cluster (and `can restart` if it auto-suspends), and `can use` to the warehouse the cluster leverages.

Complete the following steps to get your Databricks connector up and running:

1. Navigate to **Project Settings**, then select **Warehouse Sources**.
2. Click on `+ Add Connection` and select **Databricks**.
3. You should see a new page to create your databricks connector. In the first view, fill out the following fields before clicking  `Create Source`: 
    - ** Server Hostname ** - This is the hostname of your Databricks cluster. This can be found in your workspace URL, or by navigating to [JDBC/ODBC connection settings](https://docs.databricks.com/en/integrations/jdbc-odbc-bi.html#step)
    - ** HTTP Path ** - This is the HTTP path of the cluster you would like to connect to. This can be found in your cluster [JDBC/ODBC connection settings](https://docs.databricks.com/en/integrations/jdbc-odbc-bi.html#step)
    - ** Access Token ** - This is the Personal access token used to authenticate with your Databricks cluster. Here are the instructions on [how to create an access token](https://docs.databricks.com/en/dev-tools/auth.html#databricks-personal-access-tokens-for-workspace-users)
4. In the second view, you should see that the credentials are validated and a source is added. 
    
*IP Allowed List*
If you are using [IP Access List](https://docs.databricks.com/en/security/network/front-end/ip-access-list.html) to restrict access to your instance, you might need to add the following IP addresses to the allowed list.

```jsx
34.31.112.201
34.147.68.192
35.184.21.33
35.225.176.74
35.204.164.122
35.204.177.251
```

</Tab>
<Tab>
    
<div style={{position: 'relative', paddingBottom: '64.90384615384616%', height: 0}}>
    <iframe src="https://www.loom.com/embed/76f4658dd850457e9634c706ee0d9430"
        frameBorder="0"
        webkitallowfullscreen="true" mozallowfullscreen="true" allowFullScreen
        style={{position: 'absolute', 'top': 0, 'left': 0, 'width': '100%', 'height': '100%'}}>
    </iframe>
</div>

Complete the following steps to get your Redshift connector up and running:

1. Navigate to **Project Settings**, then select **Warehouse Sources**.
2. Click on `+ Add Connection` and select **Redshift**.
3. You should see a new page to create your Redshift connector. In the first view, fill out the following fields before clicking  `Next`: 
    - **AWS Account ID**  - This is the AWS account ID that can be found in the dropdown in the AWS Redshift Console.
    - **Cluster ID**  - This is the name of the Redshift cluster.
4. In the second view, you will need to add the following. 
    - **AWS Region** - The region code in which your Redshift cluster resides.
    - **S3 Staging Bucket** - This is the name of S3 staging bucket you need to create. We'll use it to extract data from your Redshift tables before importing the data into Mixpanel.
    - Copy the command generated below in the AWS CLI to create the S3 Staging Bucket with the name you specified.
    - **Database Name** - Input the name of the Database where the tables you want to import are stored.
    - (Optional) **Policy Name** - This is an optional name for the policy, which contains role permissions that you need to grant the Mixpanel Service Account. After inputting a policy name, you can either copy paste the JSON in the AWS UI or copy paste the inline command line version that we generate and run in the AWS CLI.
    - **Role Name** - Input the name of the role. After inputting a role name, you can either copy paste the JSON in the AWS UI or copy paste the inline command line version that we generate and run in the AWS CLI. Running this command grants the Mixpanel Service Account the necessary permissions to read and export data from your Redshift tables.
    - Finally, attach the policy you created to the role you created by copy pasting the command in the AWS CLI.
    - Then, click Create Source.
5. In the third view, you should see a confirmation that your source was created. To establish the source connection, we need to ping your Redshift instance to actually create the service account user.
    - **Grant Access to Schema** - Enter the name of the schema you want to grant Mixpanel access to. 
    - Copy the command generated and run in your Redshift worksheet. Once that command is run successfully, the connection will be established and you will be able to send data from Redshift tables to Mixpanel.
    
### IP Allowed List
If you are using [AWS PrivateLink](https://docs.aws.amazon.com/redshift/latest/mgmt/security-private-link.html) to restrict access to your instance, you might need to add the following IP addresses to the allowed list.

```jsx
34.31.112.201
34.147.68.192
35.184.21.33
35.225.176.74
35.204.164.122
35.204.177.251
```
</Tab>
</ExtendedTabs>

## Table Types

Mixpanel’s [Data Model](/docs/how-it-works/concepts) consists of 4 types: Events, User Profiles, Group Profiles, and Lookup Tables. Each have properties, which are arbitrary JSON. Warehouse Connectors lets you turn any table or view in your warehouse into one of these 4 types of tables, provided they match the required schema.

### Events

An event is something that happens at a point in time. It’s akin to a “fact” in dimensional modeling or a log in a database. Events have properties, which describe the event. Learn more about Events [here](/docs/data-structure/events-and-properties).

Here’s an example table that illustrates what can be loaded as events in Mixpanel. The most important fields are the timestamp (when) and the user id (who) — everything else is optional.

| Timestamp | User ID | Item | Brand | Amount | Type |
| --- | --- | --- | --- | --- | --- |
| 2024-01-04 11:12:00 | alice@example.com | shoes | nike | 99.23 | in-store |
| 2024-01-12 11:12:00 | bob@example.com | socks | adidas | 4.56 | online |

Here are more details about the schema we expect for events:

| Column | Required | Type | Description |
| --- | --- | --- | --- |
| Event Name | Yes | String | The name of the event. Eg: Purchase Completed or Support Ticket Filed. Note: you can specify this value statically, it doesn’t need to be a column in the table. |
| Time | Yes | Timestamp | The time at which the event occurred. |
| User ID | No | String or Integer | The unique identifier of the user who performed the event. Eg: 12345 or grace@example.com. |
| Device ID | No | String or Integer | An identifier for anonymous users, useful for tracking pre-login data. Learn more [here](/docs/tracking-methods/id-management/identifying-users) |
| JSON Properties | No | JSON or Variant | A field that contains key-value properties in JSON format. If provided, Mixpanel will flatten this field out into properties. |
| All other columns | No | Any | These can be anything. Mixpanel will auto-detect these columns and attach them to the event as properties. |

### User Profiles

A User Profile is a table that describes your users. It’s akin to a “dimension” in dimensional modeling or a relational table in a database. Learn more about User Profiles [here](/docs/data-structure/user-profiles).

Here’s an example table that illustrates what can be loaded as user profiles in Mixpanel. The only important column is the User ID, which is the primary key of the table.

| User ID | Email | Name | Subscription Tier |
| --- | --- | --- | --- |
| 12345 | grace@example.com | Grace Hopper | Pro |
| 45678 | bob@example.com | Bob Noyce | Free |

<Callout type="info">
Profile History is in beta. While Profiles typically only store the state of a user *as of now*, Profile History enables storing the state of a user *over time*. When creating a User Profile sync, set the Table Type to “History Table” — this will require you to supply a Start Time column in the sync configuration. Request beta access [here](https://forms.gle/x8mbU6FVe5uHiVXF6).
</Callout>

### Group Profiles

A Group Profile is a table that describes an entity (most often an Account, if you’re a B2B company). They are functionally identical to User Profiles, just used for other non-User entities. Group Profiles are only available if you have the Group Analytics add-on. Learn more about Group Analytics [here](/docs/data-structure/advanced/group-analytics).

Here’s an example table that illustrates what can be loaded as group profiles in Mixpanel. The only important column is the Group Key, which is the primary key of the table.

| Group Key | Name | Domain | ARR | Subscription Tier |
| --- | --- | --- | --- | --- |
| 12345 | Notion | notion.so | 45000 | Enterprise |
| 45678 | Linear | linear.so | 2000 | Pro |

### Lookup Tables

A Lookup Table is a table that describes an entity. It’s useful for enriching events with metadata about other concepts in your product, like content or skus. Learn more about Lookup Tables [here](https://docs.mixpanel.com/docs/data-structure/lookup-tables).

Here’s an example table that illustrates what can be loaded as group profiles in Mixpanel. The only important column is the ID, which is the primary key of the table.

| ID | Song Name | Artist | Genre |
| --- | --- | --- | --- |
| 12345 | One Dance | Drake | Pop |
| 45678 | Voyager | Daft Punk | Electronic |

## Sync Types

Warehouse Connectors continuously detect new data from your warehouse tables to load into Mixpanel. The Sync Type determines the method of detecting new rows:

### Time-Based
Time-Based syncs require an Insert Time column in your table. Mixpanel remembers the maximum Insert Time it saw in the previous run of the sync and looks for only rows that have an Insert Time greater than that. This is useful and efficient for append-only tables (usually events) that have a column indicating when the data was appended.

### Full
Full syncs periodically make a snapshot of the source table and sync it entirely to Mixpanel. If a row has new properties in your warehouse, the corresponding profile in Mixpanel will be overridden with those new properties. This mode is available for all tables except events.

### Mirror
Mirror syncs leverage warehouse change-data-capture (CDC) capabilities to mirror insert, updates, and deletes from your warehouse to Mixpanel. It provides the efficiency of time-based syncs with the simplicity/reliability of full syncs and works for all table types.

<Callout type="info">
Mirror is in beta for Snowflake only. Request access [here](https://forms.gle/x8mbU6FVe5uHiVXF6).
</Callout>


## FAQ

### What tables are valuable to load into Mixpanel?
Anything that is event-based (has a user_id and timestamp) and that you want to analyze in Mixpanel. Examples, by data source are:
* CRM: Opportunity Created, Opportunity Closed
* Support: Ticket Created, Ticket Closed
* Billing: Subscription Created, Subscription Upgraded, Subscription Canceled, Payment Made
* Appplication Database: Signup, Purchased Item, Invited Teammate

We also recommend loading your user and account tables, to enrich events with demographic attributes about the users and accounts who performed them.

### How fast do syncs run?

Syncs have a throughput of ~30K events/second or ~100M events/hour.

### I already track data to Mixpanel via SDK or CDP, can I still use Warehouse Connectors?

Yes! You can send some events (eg: web and app data) directly via our SDKs and send other data (eg: user profiles from CRM or logs from your backend) from your warehouse and analyze them together in Mixpanel.

### How much does Warehouse Connectors cost?
The events generated by Warehouse Connectors are billed identically to all other events you track to Mixpanel. Learn more about Mixpanel’s event-based billing [here](https://docs.mixpanel.com/docs/pricing/billing). Otherwise, there is no special cost for using Warehouse Connectors.

### What will be the impact of this on my existing DWH bill?

Very little. We’ve designed Warehouse Connectors to make highly efficient queries to extract new data from your warehouse. To be extra careful, provision the smallest possible warehouse for use with Warehouse Connectors. If syncs run slowly with this size, you can scale up to trade cost for speed.

### How can I get help setting up a warehouse sync?

[Reach out](https://mixpanel.com/contact-us/sales/) to our team — we’re happy to walk you through the set up. If you bring a data engineer who has credentials to access your warehouse, it takes < 10 minutes to get up and running.
